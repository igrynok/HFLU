{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz+cksWAACeSf8QhRuYADy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igrynok/HFLU/blob/main/Assignment1_Face_Detection_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe"
      ],
      "metadata": {
        "id": "RpuBokMRxbZS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d173061a"
      },
      "source": [
        "## Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import mediapipe as mp\n",
        "from retinaface import RetinaFace\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_OKNW3cGT2dh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97a7828"
      },
      "source": [
        "## Load Images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Please click 'Choose Files' and select 'group_image.jpg' and 'crowded_stadium.jpg'\")\n",
        "# This will open a widget to upload files from your computer\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "3B3O9avOdURw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename1 = \"group_image.jpg\"\n",
        "filename2 = \"crowded_stadium.jpg\"\n",
        "\n",
        "img1 = cv2.imread(filename1)\n",
        "img2 = cv2.imread(filename2)\n",
        "\n",
        "# Verify loading was successful\n",
        "if img1 is None:\n",
        "    print(f\"ERROR: Could not load {filename1}. Check if the file name matches exactly.\")\n",
        "elif img2 is None:\n",
        "    print(f\"ERROR: Could not load {filename2}. Check if the file name matches exactly.\")\n",
        "else:\n",
        "    print(f\"SUCCESS: Loaded img1 {img1.shape} and img2 {img2.shape} globally.\")\n",
        "\n",
        "    img1_disp = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "    img2_disp = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    # Display Image 1\n",
        "    ax[0].imshow(img1_disp)\n",
        "    ax[0].set_title(f\"img1: Group Image\\n{img1.shape}\", fontsize=14)\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # Display Image 2\n",
        "    ax[1].imshow(img2_disp)\n",
        "    ax[1].set_title(f\"img2: Crowded Stadium\\n{img2.shape}\", fontsize=14)\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UZWGa3oGX8pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9605b382"
      },
      "source": [
        "## TEST 1: VIOLA-JONES (Baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To complete the exercises follow the steps:\n",
        "\n",
        "*   Initialize CascadeClassifier with 'haarcascade_frontalface_default.xml'\n",
        "*   Convert image to grayscale\n",
        "*   Run detectMultiScale (try scaleFactor=1.1, minNeighbors=4)\n",
        "*   Save the count of faces found and time needed find faces\n",
        "*   Dispaly images with the bounding boxes found      \n"
      ],
      "metadata": {
        "id": "RFsAb6EAfuZy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6N7G4KoyAXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST 2: MEDIAPIPE"
      ],
      "metadata": {
        "id": "Ln18bxseie59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To complete the exercises follow the steps:\n",
        "\n",
        "*   Initialize MediaPipe FaceDetection (use model_selection=1 for long range!)\n",
        "*   Convert image to RGB\n",
        "*   Process the image\n",
        "*   Save the count of detections and time needed to find faces\n",
        "*   Dispaly images with the bounding boxes found"
      ],
      "metadata": {
        "id": "rhG32Agki7Og"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qLyDzaxtyBNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}